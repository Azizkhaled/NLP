{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPy0M7yhKdrBhuo4Oq+FMvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azizkhaled/NLP_with_Aziz/blob/main/MLM_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg6atzKjq6l2",
        "outputId": "027e765c-e239-4efb-98d9-5ec7665e2d12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Rek7rzetoVzY"
      },
      "outputs": [],
      "source": [
        "from transformers import  BertTokenizer, BertForMaskedLM\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1: simple text and concept explaination"
      ],
      "metadata": {
        "id": "V6sUVgy7kuCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initailize tokenizer and model"
      ],
      "metadata": {
        "id": "xj_1ZDUWb9cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "text = (\"On social [MASK], thousands of people from around the globe condemned Israel’s latest deadly\"\n",
        " \"attacks on the Palestinians. Despite relentless attempts by Israel andsocial media companies to silence them,\"\n",
        "  \"they raised awareness about Israel’s illegal [MASK] as well as its repeated violations of Palestinian human\"\n",
        "   \"[MASK] and international law.\")\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO1I1xXbVzoq",
        "outputId": "d472ef0a-3bef-44ce-f2c4-cf195594c442"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "id": "LvD05JAAWAf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcd3f23-2b40-480a-e898-910b6faf665f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the logits are our MLM output"
      ],
      "metadata": {
        "id": "BWty5FAwWmZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N0nep4JWNjj",
        "outputId": "573a61b8-2d68-4294-917a-914064aec229"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 63, 30522])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify the token position where we have **[MASK]** tokens we can check the inputs tensor for tokens matching `103` (eg MASK)."
      ],
      "metadata": {
        "id": "SJZl9LpCWvqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_pos = torch.flatten((inputs.input_ids[0] == 103).nonzero()).tolist()\n",
        "mask_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndda3hLLW1zX",
        "outputId": "657c930d-4de1-429c-f4f8-c427a5180e0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 47, 57]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is for these positions that we must calculate the loss for when training our model. How does that work? Well, we compare the inputs at those two positions, to the predicted outputs at those two positions - converted to one-hot encoding and probability distribution respectively."
      ],
      "metadata": {
        "id": "uM5Da4EDbTdn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomly mask tokens"
      ],
      "metadata": {
        "id": "BbvpyKfxb6FB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In reality, we must mask our tokens randomly, after which we feed in the original (unmasked) token_ids into to model as labels, and keep token_ids as the new masked tensor.\n",
        "\n",
        "To test this, let's unmask our text first."
      ],
      "metadata": {
        "id": "od2eEygabfWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\"On social media, thousands of people from around the globe condemned Israel’s latest deadly\"\n",
        " \"attacks on the Palestinians. Despite relentless attempts by Israel andsocial media companies to silence them,\"\n",
        "  \"they raised awareness about Israel’s illegal occupation as well as its repeated violations of Palestinian human\"\n",
        "   \"rights and international law.\")"
      ],
      "metadata": {
        "id": "weWRJfXGW3cn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now convert our text using the tokenizer:"
      ],
      "metadata": {
        "id": "1m_UAQuEblks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text, return_tensors='pt')"
      ],
      "metadata": {
        "id": "FlAvxYbHbhFn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the inputs into labels before masking to be our base truth"
      ],
      "metadata": {
        "id": "B4GJsf5ld7Zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs['labels'] = inputs.input_ids.detach().clone()\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T05fc1N4bm8H",
        "outputId": "7ec27538-b22d-4962-edba-c1057ffcaec4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2006,  2591,  2865,  1010,  5190,  1997,  2111,  2013,  2105,\n",
              "          1996,  7595, 10033,  3956,  1521,  1055,  6745,  9252, 19321,  8684,\n",
              "          2015,  2006,  1996, 21524,  1012,  2750, 21660,  4740,  2011,  3956,\n",
              "          1998,  6499, 13247,  2865,  3316,  2000,  4223,  2068,  1010,  2027,\n",
              "          2992,  7073,  2055,  3956,  1521,  1055,  6206,  6139,  2004,  2092,\n",
              "          2004,  2049,  5567, 13302,  1997,  9302,  2529, 15950,  2015,  1998,\n",
              "          2248,  2375,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2006,  2591,  2865,  1010,  5190,  1997,  2111,  2013,  2105,\n",
              "          1996,  7595, 10033,  3956,  1521,  1055,  6745,  9252, 19321,  8684,\n",
              "          2015,  2006,  1996, 21524,  1012,  2750, 21660,  4740,  2011,  3956,\n",
              "          1998,  6499, 13247,  2865,  3316,  2000,  4223,  2068,  1010,  2027,\n",
              "          2992,  7073,  2055,  3956,  1521,  1055,  6206,  6139,  2004,  2092,\n",
              "          2004,  2049,  5567, 13302,  1997,  9302,  2529, 15950,  2015,  1998,\n",
              "          2248,  2375,  1012,   102]])}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create random array of floats in equal dimension to input_ids\n",
        "rand = torch.rand(inputs.input_ids.shape)\n",
        "rand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUPTIJpboVH",
        "outputId": "03db3b69-3cfd-41ef-aa4c-f6e6c38eb9c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6923, 0.8197, 0.7476, 0.0119, 0.0370, 0.9191, 0.3837, 0.9546, 0.1439,\n",
              "         0.5977, 0.8921, 0.1550, 0.1029, 0.6082, 0.8608, 0.7427, 0.9155, 0.4344,\n",
              "         0.1660, 0.0449, 0.5158, 0.3124, 0.1385, 0.1940, 0.7310, 0.8536, 0.8797,\n",
              "         0.7057, 0.8805, 0.1790, 0.7181, 0.0762, 0.3261, 0.2381, 0.4109, 0.1451,\n",
              "         0.0927, 0.5450, 0.7416, 0.3041, 0.9239, 0.5813, 0.7397, 0.1297, 0.4223,\n",
              "         0.5359, 0.4041, 0.3880, 0.8068, 0.2648, 0.2100, 0.5945, 0.5983, 0.5385,\n",
              "         0.4520, 0.5081, 0.3499, 0.5901, 0.2262, 0.1826, 0.3845, 0.3542, 0.1545,\n",
              "         0.8378]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# where the random array is less than 0.15, we set true, these will be our MASK tokens\n",
        "# make sure we don't mask the CLS (101) and SEP tokens (102)\n",
        "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
        "mask_arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxWdXzHAccqH",
        "outputId": "45571cfb-02cf-4b5a-ed03-c3df2884495d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False,  True,  True, False, False, False,  True, False,\n",
              "         False, False,  True, False, False, False, False, False, False,  True,\n",
              "         False, False,  True, False, False, False, False, False, False, False,\n",
              "         False,  True, False, False, False,  True,  True, False, False, False,\n",
              "         False, False, False,  True, False, False, False, False, False, False,\n",
              "         False, False, False, False, False, False, False, False, False, False,\n",
              "         False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the indieces to be masked\n",
        "\n",
        "selection = torch.flatten((mask_arr[0]).nonzero()).tolist()\n",
        "selection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g1oRGtkdWY7",
        "outputId": "e0acec59-78d5-45dc-d170-258f4423dbd0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 8, 12, 19, 22, 31, 35, 36, 43]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.input_ids[0, selection] = 103\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2bj6RnUcqqO",
        "outputId": "9b6e9446-559d-4392-a7ac-aa1d39e4347a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2006,  2591,   103,   103,  5190,  1997,  2111,   103,  2105,\n",
              "          1996,  7595,   103,  3956,  1521,  1055,  6745,  9252, 19321,   103,\n",
              "          2015,  2006,   103, 21524,  1012,  2750, 21660,  4740,  2011,  3956,\n",
              "          1998,   103, 13247,  2865,  3316,   103,   103,  2068,  1010,  2027,\n",
              "          2992,  7073,  2055,   103,  1521,  1055,  6206,  6139,  2004,  2092,\n",
              "          2004,  2049,  5567, 13302,  1997,  9302,  2529, 15950,  2015,  1998,\n",
              "          2248,  2375,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2006,  2591,  2865,  1010,  5190,  1997,  2111,  2013,  2105,\n",
              "          1996,  7595, 10033,  3956,  1521,  1055,  6745,  9252, 19321,  8684,\n",
              "          2015,  2006,  1996, 21524,  1012,  2750, 21660,  4740,  2011,  3956,\n",
              "          1998,  6499, 13247,  2865,  3316,  2000,  4223,  2068,  1010,  2027,\n",
              "          2992,  7073,  2055,  3956,  1521,  1055,  6206,  6139,  2004,  2092,\n",
              "          2004,  2049,  5567, 13302,  1997,  9302,  2529, 15950,  2015,  1998,\n",
              "          2248,  2375,  1012,   102]])}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pass these inputs into our model"
      ],
      "metadata": {
        "id": "pFRoKFdeeR9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "outputs.keys()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcbPeQPnds-m",
        "outputId": "ccbf0e2d-f431-4c9f-da4f-35383c08e3e0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['loss', 'logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXNmAQQ9eePH",
        "outputId": "3052a826-ea17-42a1-93c9-75338b0a7528"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.8564, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is this loss that we will be training on."
      ],
      "metadata": {
        "id": "FUEmGTOPeiqs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "amYiYPEulRCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}