{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (1.19.2)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (2.24.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (8.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\acer\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->torchvision) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initilize the connection with ElasticSearch\n",
    "\n",
    "We already know that in open-domain Q&A, we typically design a model architecture that contains a data source, retriever, and reader/generator.\n",
    "\n",
    "The first of these components is our document store. The two most popular stores are Elasticsearch and FAISS. FAISS is better but requires linux system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/18/2023 12:35:17 - INFO - elasticsearch -   HEAD http://localhost:9200/squad_docs [status:200 request:0.010s]\n",
      "08/18/2023 12:35:17 - INFO - elasticsearch -   GET http://localhost:9200/squad_docs [status:200 request:0.004s]\n",
      "08/18/2023 12:35:17 - INFO - elasticsearch -   PUT http://localhost:9200/squad_docs/_mapping [status:200 request:0.022s]\n",
      "08/18/2023 12:35:17 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.006s]\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "\n",
    "# initialize FAISS\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host = 'localhost',\n",
    "    username='', password='', \n",
    "    index='squad_docs'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Passage Retriever (DPR)\n",
    "\n",
    " DPR is converting the question you have provided into an approximate context. \n",
    "\n",
    " The job of the retriever is to filter through our document store for relevant chunks of information (the documents) and pass them to the reader/generator model.\n",
    "\n",
    " The job of the retriever is critical to our reader performance. Given a query, it must find the most relevant contexts.\n",
    "\n",
    " DPR is an alternative to the traditional TF-IDF and BM25 techniques for passage retrieval. \n",
    " DPR works by using two unique BERT encoder models. One of those models - Eᴘ - encodes passages of text into an encoded passage vector (we store context vectors in our document store).\n",
    "\n",
    "The other model - EQ - maps a question into an encoded question vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "# initialize DPR model\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model='facebook/dpr-question_encoder-single-nq-base',\n",
    "    passage_embedding_model='facebook/dpr-ctx_encoder-single-nq-base',\n",
    "    use_gpu=True,\n",
    "    embed_title=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/18/2023 12:48:24 - INFO - elasticsearch -   POST http://localhost:9200/squad_docs/_count [status:200 request:0.131s]\n",
      "08/18/2023 12:48:24 - INFO - haystack.document_store.elasticsearch -   Updating embeddings for 1204 docs ...\n",
      "08/18/2023 12:48:24 - INFO - elasticsearch -   POST http://localhost:9200/squad_docs/_search?scroll=1d&size=10000 [status:200 request:0.259s]\n",
      "08/18/2023 12:48:24 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.020s]\n",
      "08/18/2023 12:48:24 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.007s]\n",
      "Creating Embeddings: 100%|██████████| 76/76 [04:25<00:00,  3.49s/ Batches]\n",
      "08/18/2023 12:53:00 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:5.357s]\n",
      "08/18/2023 12:53:06 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:4.817s]\n",
      "08/18/2023 12:53:08 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.937s]\n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader/ Generator model \n",
    "\n",
    "The reader/generator model is the final model in our Q&A stack. We can either have a reader, which extracts an answer directly from the context. Or, a generator, which uses language generation to generate an answer from the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/18/2023 12:53:08 - INFO - farm.utils -   Using device: CUDA \n",
      "08/18/2023 12:53:08 - INFO - farm.utils -   Number of GPUs: 1\n",
      "08/18/2023 12:53:08 - INFO - farm.utils -   Distributed Training: False\n",
      "08/18/2023 12:53:08 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "08/18/2023 12:53:20 - WARNING - farm.utils -   ML Logging is turned off. No parameters, metrics or artifacts will be logged to MLFlow.\n",
      "08/18/2023 12:53:20 - INFO - farm.utils -   Using device: CUDA \n",
      "08/18/2023 12:53:20 - INFO - farm.utils -   Number of GPUs: 1\n",
      "08/18/2023 12:53:20 - INFO - farm.utils -   Distributed Training: False\n",
      "08/18/2023 12:53:20 - INFO - farm.utils -   Automatic Mixed Precision: None\n",
      "08/18/2023 12:53:20 - INFO - farm.infer -   Got ya 3 parallel workers to do inference ...\n",
      "08/18/2023 12:53:20 - INFO - farm.infer -    0    0    0 \n",
      "08/18/2023 12:53:20 - INFO - farm.infer -   /w\\  /w\\  /w\\\n",
      "08/18/2023 12:53:20 - INFO - farm.infer -   /'\\  / \\  /'\\\n",
      "08/18/2023 12:53:20 - INFO - farm.infer -       \n"
     ]
    }
   ],
   "source": [
    "from haystack.reader.farm import FARMReader\n",
    "reader = FARMReader(model_name_or_path='deepset/bert-base-cased-squad2', use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reader retriever pipeline with Haystack\n",
    "\n",
    "Haystack comes with a very convenient ExtractiveQAPipeline class which allows us to pass our reader and retriever to build an easy-to-use extractive Q&A pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.pipeline import ExtractiveQAPipeline\n",
    "\n",
    "pipeline = ExtractiveQAPipeline(reader=reader, retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Embeddings: 100%|██████████| 1/1 [00:00<00:00,  6.99 Batches/s]\n",
      "08/18/2023 13:01:57 - INFO - elasticsearch -   POST http://localhost:9200/squad_docs/_search [status:200 request:0.024s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.62 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.20 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  6.54 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  7.35 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  8.70 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.20 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 10.00 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.05 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 12.05 Batches/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is love?',\n",
       " 'no_ans_gap': -11.4096097946167,\n",
       " 'answers': [{'answer': 'non-human primates',\n",
       "   'score': -4.089797496795654,\n",
       "   'probability': 0.3749064741977998,\n",
       "   'context': 'f their forested territories. Meanwhile, the relationship between non-human primates in the subsistence and symbolism of indigenous lowland South Amer',\n",
       "   'offset_start': 66,\n",
       "   'offset_end': 84,\n",
       "   'offset_start_in_doc': 347,\n",
       "   'offset_end_in_doc': 365,\n",
       "   'document_id': 'bb040628-4c48-4ddf-92f2-ca03d0ab87e5',\n",
       "   'meta': {}},\n",
       "  {'answer': 'Hugo',\n",
       "   'score': -6.5083818435668945,\n",
       "   'probability': 0.3071350115399719,\n",
       "   'context': 'Janet Gray and other supporters of the hypothesis suggest that the name huguenote would be roughly equivalent to little Hugos, or those who want Hugo.',\n",
       "   'offset_start': 145,\n",
       "   'offset_end': 149,\n",
       "   'offset_start_in_doc': 587,\n",
       "   'offset_end_in_doc': 591,\n",
       "   'document_id': '6580fe1b-bbaa-4342-8c8d-e16735ddfd56',\n",
       "   'meta': {}},\n",
       "  {'answer': 'first body exerts a force F on a second body',\n",
       "   'score': -8.429624557495117,\n",
       "   'probability': 0.25851464405592195,\n",
       "   'context': 'ce or a force that acts on only one body. Whenever a first body exerts a force F on a second body, the second body exerts a force −F on the first body',\n",
       "   'offset_start': 53,\n",
       "   'offset_end': 97,\n",
       "   'offset_start_in_doc': 335,\n",
       "   'offset_end_in_doc': 379,\n",
       "   'document_id': '8aba9ae2-d829-4ce0-88d7-862759f3796b',\n",
       "   'meta': {}}]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.run(query='What is love?', top_k_reader=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
