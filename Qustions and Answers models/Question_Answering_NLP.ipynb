{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPUSpSwdNfrdXINbC0LwuSO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azizkhaled/NLP-with-Aziz/blob/main/Question_Answering_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open Domain Quesion Answering (ODQA)"
      ],
      "metadata": {
        "id": "qJlWCo5O2YyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: SQuAD\n",
        "\n",
        "The SQuAD (Stanford Question and Answering Dataset) is a hugely popular dataset containing question and answer pairs scraped from Wikipedia, covering topics ranging from Beyonce, to Physics."
      ],
      "metadata": {
        "id": "LP75rqYf3ryJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the data"
      ],
      "metadata": {
        "id": "yk3o22tC4MHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://rajpurkar.github.io/SQuAD-explorer/dataset/'\n",
        "files = ['train-v2.0.json', 'dev-v2.0.json']"
      ],
      "metadata": {
        "id": "jQt5sSYU3rj6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "squad_dir = './data/squad'\n",
        "\n",
        "os.mkdir(squad_dir)"
      ],
      "metadata": {
        "id": "cy79WcZLzAw0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "for file in files:\n",
        "    res = requests.get(url+file)\n",
        "    # write to file in chunks\n",
        "    with open(os.path.join(squad_dir, file), 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size=40):\n",
        "            f.write(chunk)"
      ],
      "metadata": {
        "id": "CGSGk1a-4Uoe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(os.path.join(squad_dir, 'train-v2.0.json'), 'rb') as f:\n",
        "    squad = json.load(f)"
      ],
      "metadata": {
        "id": "uoM8o6-C48m3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reorganize the Train data"
      ],
      "metadata": {
        "id": "xXpaVZJq-CJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize list where we will place all of our data\n",
        "new_squad = []\n",
        "\n",
        "# we need to loop through groups -> paragraphs -> qa_pairs\n",
        "for group in squad['data']:\n",
        "    for paragraph in group['paragraphs']:\n",
        "        # we pull out the context from here\n",
        "        context = paragraph['context']\n",
        "        for qa_pair in paragraph['qas']:\n",
        "            # we pull out the question\n",
        "            question = qa_pair['question']\n",
        "            # now the logic to check if we have 'answers' or 'plausible_answers'\n",
        "            if 'answers' in qa_pair.keys() and len(qa_pair['answers']) > 0:\n",
        "                answer = qa_pair['answers'][0]['text']\n",
        "            elif 'plausible_answers' in qa_pair.keys() and len(qa_pair['plausible_answers']) > 0:\n",
        "                answer = qa_pair['plausible_answers'][0]['text']\n",
        "            else:\n",
        "                # this shouldn't happen, but just in case we just set answer = None\n",
        "                answer = None\n",
        "            # append dictionary sample to parsed squad\n",
        "            new_squad.append({\n",
        "                'question': question,\n",
        "                'answer': answer,\n",
        "                'context': context\n",
        "            })"
      ],
      "metadata": {
        "id": "tQ2kM2TM52z3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the train data"
      ],
      "metadata": {
        "id": "UAmQiA3g_LrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(squad_dir, 'train.json'), 'w') as f:\n",
        "    json.dump(new_squad, f)"
      ],
      "metadata": {
        "id": "DhOMVKU295p3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Same operation for dev data"
      ],
      "metadata": {
        "id": "3i6yUdHb_Nt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(squad_dir, 'dev-v2.0.json'), 'rb') as f:\n",
        "    squad_dev = json.load(f)"
      ],
      "metadata": {
        "id": "z8tCyOUc_ZkF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_dev['data'][0]['paragraphs'][0]"
      ],
      "metadata": {
        "id": "-zL4tP7B_iy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize list where we will place all of our data\n",
        "dev_squad = []\n",
        "\n",
        "# we need to loop through groups -> paragraphs -> qa_pairs\n",
        "for group in squad_dev['data']:\n",
        "    for paragraph in group['paragraphs']:\n",
        "        # we pull out the context from here\n",
        "        context = paragraph['context']\n",
        "        for qa_pair in paragraph['qas']:\n",
        "            # we pull out the question\n",
        "            question = qa_pair['question']\n",
        "            # now the logic to check if we have 'answers' or 'plausible_answers'\n",
        "            if 'answers' in qa_pair.keys() and len(qa_pair['answers']) > 0:\n",
        "              #get all answers\n",
        "                answer = [answer['text'] for answer in qa_pair['answers']]\n",
        "            elif 'plausible_answers' in qa_pair.keys() and len(qa_pair['plausible_answers']) > 0:\n",
        "                #get all answers\n",
        "                answer = [answer['text'] for answer in qa_pair['plausible_answers']]\n",
        "            else:\n",
        "                # this shouldn't happen, but just in case we just set answer = None\n",
        "                answer = []\n",
        "\n",
        "            # append dictionary sample to parsed squad\n",
        "            dev_squad.append({\n",
        "                'question': question,\n",
        "                'answers': list(set(answer)), #convert to set to remove duplicates\n",
        "                'context': context\n",
        "            })"
      ],
      "metadata": {
        "id": "Elhw5pXv-IlG"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_squad"
      ],
      "metadata": {
        "id": "rEepKW9hBPFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(squad_dir, 'dev.json'), 'w') as f:\n",
        "    json.dump(dev_squad, f)"
      ],
      "metadata": {
        "id": "JJ95ybdeBeoW"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question Answering with Bert Transformet model"
      ],
      "metadata": {
        "id": "po_X0hS3Frxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our first QA model we will setup a simple question-answering pipeline using HuggingFace transformers and a pretrained BERT model. We will be testing it on our SQuAD data so let's load that first."
      ],
      "metadata": {
        "id": "tVoBDBypGP3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the model"
      ],
      "metadata": {
        "id": "zrJuaiqbGSc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEs4eATlGjQr",
        "outputId": "f1cd2a58-b5e2-4c0c-cee3-837058f7a09e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForQuestionAnswering\n",
        "\n",
        "# we can get these models from hugging face\n",
        "modelname = 'deepset/bert-base-cased-squad2'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(modelname)\n",
        "model = BertForQuestionAnswering.from_pretrained(modelname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK3Bbm4GFcMv",
        "outputId": "9bda641b-451a-412f-a102-cb838310406e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data pipeline"
      ],
      "metadata": {
        "id": "BhkBIGq_JdFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa = pipeline('question-answering', model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RFLceoUGhU_",
        "outputId": "cd0801f7-a753-49f7-eaa0-1c27aa2e61f1"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./data/squad/dev.json', 'r') as f:\n",
        "    squad = json.load(f)"
      ],
      "metadata": {
        "id": "kb2L_4NZJm4U"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "2gYP-TyJKMWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QA = []\n",
        "\n",
        "for pair in squad[25:30]:\n",
        "    # pass in our question and context to return an answer\n",
        "    ans = qa({\n",
        "        'question': pair['question'],\n",
        "        'context': pair['context']\n",
        "    })\n",
        "    # append predicted answer and real to answers list\n",
        "    QA.append({\n",
        "        'Question': pair['question'],\n",
        "        'predicted': ans['answer'],\n",
        "        'true': pair['answers']\n",
        "    })"
      ],
      "metadata": {
        "id": "oBMRrDqxJnxW"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECSi55kUKOxe",
        "outputId": "f9d52229-d455-412a-f704-83e661709de8"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Question': 'What treaty was established in the 9th century?',\n",
              "  'predicted': 'the treaty of Saint-Clair-sur-Epte',\n",
              "  'true': ['treaty of Saint-Clair-sur-Epte']},\n",
              " {'Question': 'Who established a treaty with King Charles the third of France?',\n",
              "  'predicted': 'Charles III of West Francia and the famed Viking ruler Rollo,',\n",
              "  'true': ['Rollo']},\n",
              " {'Question': 'What did the French promises to protect Rollo and his men from?',\n",
              "  'predicted': 'Viking incursions.',\n",
              "  'true': ['further Viking incursions.']},\n",
              " {'Question': 'Who upon arriving gave the original viking settlers a common identity?',\n",
              "  'predicted': '\"Frankish\".',\n",
              "  'true': ['Rollo']},\n",
              " {'Question': 'When did Rollo begin to arrive in Normandy?',\n",
              "  'predicted': 'the 880s,',\n",
              "  'true': ['880s']}]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GOOD JOB!"
      ],
      "metadata": {
        "id": "tGp3h68KLEYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VEB42mdZKZ0e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}