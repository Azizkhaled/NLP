{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOnIFnQ8MVYu+b99K5JwzCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azizkhaled/NLP_with_Aziz/blob/main/MLM_and_NSP_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For pre training BERt there are NSP (Next sentence prediction) and MLM (Mass Language Model) heads"
      ],
      "metadata": {
        "id": "Zd0ppd64oXfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg6atzKjq6l2",
        "outputId": "2cc72111-e023-4284-cc12-70c4c68dcf54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLM and NSP"
      ],
      "metadata": {
        "id": "h2CR_zyNol3B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rek7rzetoVzY"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForPreTraining\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
        "\n",
        "text = (\"After Abraham Lincoln won the November 1860 presidential [MASK] on an \"\n",
        "        \"anti-slavery platform, an initial seven slave states declared their \"\n",
        "        \"secession from the country to form the Confederacy. War broke out in \"\n",
        "        \"April 1861 when secessionist forces [MASK] Fort Sumter in South \"\n",
        "        \"Carolina, just over a month after Lincoln's inauguration.\") # 60 words the model needs to guess [MASK] after presidential,\n",
        "                                                                     # and [MASK] after forces\n",
        "\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "SawHUuiwwqwU"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1PrktHCwrbZ",
        "outputId": "86dba775-9b99-4225-e5c6-25f952d9e1c1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['prediction_logits', 'seq_relationship_logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.prediction_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auq4NVDb1QtC",
        "outputId": "a710cbe7-fa4d-45a9-8051-f950de67f98b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 62, 30522])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 62 tokens (60 + [CLS] and [SEP]), we can see this reflected in the"
      ],
      "metadata": {
        "id": "WHXxPx3i26us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.seq_relationship_logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhPbZ8Ab26eU",
        "outputId": "848ef5a5-b0cf-4b61-e15b-9f9815e560f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.8257, -1.6897]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `outputs.prediction_logits` is the output from the MLM head (vocab which maps to a word from the vocab after softmax)\n",
        "\n",
        "- `outputs.seq_relationship_logits` is the output from the NSP head (IsNext/NotNext, 0/1, as to whether it is the next sentence or not)"
      ],
      "metadata": {
        "id": "juSTnQ2b3m9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLM"
      ],
      "metadata": {
        "id": "bnra28VM38aZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the predictions into words"
      ],
      "metadata": {
        "id": "P2DpRLbd4qp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx = tokenizer.get_vocab()"
      ],
      "metadata": {
        "id": "SmPII7Uv1VM6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx.keys()"
      ],
      "metadata": {
        "id": "4p3yCxcl5fiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx['yes']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z44-Ap8H4uwJ",
        "outputId": "563e2d8e-a9a3-4d8e-f47d-95dac045524a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2748"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "teken2idx has words as keys and, lets invert it to get the words based on the tokens"
      ],
      "metadata": {
        "id": "RNCWF2rD5jGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx2token = {}\n",
        "for key, value in token2idx.items():\n",
        "  idx2token[value] = key\n"
      ],
      "metadata": {
        "id": "nt-lbohx4wR5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2token[2748]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LYfFWhcu5dgZ",
        "outputId": "03932196-6fe5-4fa1-bc3b-d6c3465dd11a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.prediction_logits[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAWMWPkBHKcN",
        "outputId": "fd3297d3-8d9f-4e59-9b9f-8405dbdf75b0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([62, 30522])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`outputs.prediction_logits` has the probabilites of each word in our tokenizer vocab (30522 words) to be a word in our text (62 words)"
      ],
      "metadata": {
        "id": "QCGdHDNkHEYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next is to extract the most probable using an argmax function:"
      ],
      "metadata": {
        "id": "BSG6iCS-Ici2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = torch.nn.functional.softmax(outputs.prediction_logits[0], dim=0)  # create probability distribution\n",
        "argmax = torch.argmax(softmax, dim=1)"
      ],
      "metadata": {
        "id": "BTmhydYp6_Rg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "argmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF_lxbQi7eOj",
        "outputId": "b0bbe76f-dd99-4234-b732-5b412fae8745"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([28191,  2348,  8181, 16628,  2180,  3882,  2281,  7313,  4883, 27419,\n",
              "         2006,  2010,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
              "         8914,  2163, 13520,  2037,  4336,  2013,  1996,  2406,  2000,  2433,\n",
              "        28775, 18179, 16363,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
              "        18232,  2923,  2749,  4548,  3481,  7680,  5017,  2005,  2148,  3792,\n",
              "        24901,  2074,  2058,  1037,  3204,  2077,  3946,  1005,  1055, 17331,\n",
              "         1025, 25656])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets use these ids to get the tokens"
      ],
      "metadata": {
        "id": "WS4NR48WIsD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in argmax:\n",
        "    print(idx2token[i.item()], end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9u8P59H7paz",
        "outputId": "8c2916f8-6863-4b42-84a1-dcd2f387dafe"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##ecin although abraham lincolnshire won 1948 november 1860 presidential primaries on his anti - slavery platform , an initial seven tributary states declare their independence from the country to form ##ici confederacy ##yre war broke out in april 1861 when ##oya ##ist forces occupied fort sum ##mer for south carolina ##trip just over a month before grant ' s inauguration ; ##tson "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guesses were: primaries and occupied\n",
        "\n",
        "the correct words were election and attacked. very close guesses"
      ],
      "metadata": {
        "id": "VXN3eWJYJrlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "srliMmwK9Skh",
        "outputId": "f9823d82-cda3-4897-9334-969e01d1b2a8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"After Abraham Lincoln won the November 1860 presidential [MASK] on an anti-slavery platform, an initial seven slave states declared their secession from the country to form the Confederacy. War broke out in April 1861 when secessionist forces [MASK] Fort Sumter in South Carolina, just over a month after Lincoln's inauguration.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NSP"
      ],
      "metadata": {
        "id": "Eb9GvYdSKcf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next sentence prediction is slightly different. First, we need to define the two sequences, which we must split using a **[SEP]** token and differentiate using the `token_type_ids` tensor."
      ],
      "metadata": {
        "id": "wmdq47vyKpLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text0 = (\"After Abraham Lincoln won the November 1860 presidential [MASK] on an \"\n",
        "        \"anti-slavery platform, an initial seven slave states declared their \"\n",
        "        \"secession from the country to form the Confederacy.\")\n",
        "text1 = (\"War broke out in April 1861 when secessionist forces [MASK] Fort \"\n",
        "         \"Sumter in South Carolina, just over a month after Lincoln's \"\n",
        "         \"inauguration.\")\n",
        "text2 = (\"A random text to test the NSP algorithim\")"
      ],
      "metadata": {
        "id": "XAdtGymrKQbg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text0, text1, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "id": "K_mhvLTfK3yL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGCXLapxQ8xL",
        "outputId": "bae69364-dd30-44ec-946d-f236186034c2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,   103,\n",
              "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
              "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
              "          1996, 18179,  1012,   102,  2162,  3631,  2041,  1999,  2258,  6863,\n",
              "          2043, 22965,  2923,  2749,   103,  3481,  7680,  3334,  1999,  2148,\n",
              "          3792,  1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055,\n",
              "         17331,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`token_type_ids` = 0, thats for the text0.\n",
        "\n",
        "`token_type_ids` = 1, thats for the text1.\n",
        "\n",
        "also notice the aditional 102, which a [SEP] token"
      ],
      "metadata": {
        "id": "2AmfvNLoRNWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "OI2Wrx_hRDSY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.seq_relationship_logits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tovo2-AR8qB",
        "outputId": "320b419d-af9e-49a1-a71f-2898c0507935"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.0843, -5.6813]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, now we process them through a argmax function to get 0/1 as to whether sentence B follows sentence A (marked by 0 in token_type_ids)."
      ],
      "metadata": {
        "id": "OfjocEnhSaHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "argmax = torch.argmax(outputs.seq_relationship_logits)  # get index of the max activation\n",
        "'NotNext' if argmax.item() else 'IsNext'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MsmRzhJIR_KR",
        "outputId": "5f52c053-3f91-425c-eb06-bccf4b635989"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IsNext'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Index 0 represents BERTs IsNext class, meaning that sentence B is the next sentence after A. Index 1 represents the NotNext class, meaning sentence B is not the next sentence after B. |"
      ],
      "metadata": {
        "id": "53vbUEOSSfNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let test it with a a random text"
      ],
      "metadata": {
        "id": "CC2wxM2KS2MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text0, text2, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "argmax = torch.argmax(outputs.seq_relationship_logits)  # get index of the max activation\n",
        "'NotNext' if argmax.item() else 'IsNext'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HwloY46uSNVR",
        "outputId": "9e28060a-6cf3-4195-a482-dd51eb8ae325"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NotNext'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect !"
      ],
      "metadata": {
        "id": "Awe8kvuBTHxM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z_SUhxUATDBh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}